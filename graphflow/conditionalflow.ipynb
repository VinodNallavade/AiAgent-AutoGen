{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbfc9e52",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m team.run_stream(task=\u001b[33m\"\u001b[39m\u001b[33mAutoGen is a framework for building AI agents.\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     57\u001b[39m         \u001b[38;5;28mprint\u001b[39m(event)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m main()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmain\u001b[39m():\n\u001b[32m     30\u001b[39m     \u001b[38;5;66;03m# Initialize agents with OpenAI model clients.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     model_client = \u001b[43mOpenAIChatCompletionClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4.1-nano\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     agent_a = AssistantAgent(\n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mA\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     34\u001b[39m         model_client=model_client,\n\u001b[32m     35\u001b[39m         system_message=\u001b[33m\"\u001b[39m\u001b[33mDetect if the input is in Chinese. If it is, say \u001b[39m\u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, else say \u001b[39m\u001b[33m'\u001b[39m\u001b[33mno\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, and nothing else.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     36\u001b[39m     )\n\u001b[32m     37\u001b[39m     agent_b = AssistantAgent(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m, model_client=model_client, system_message=\u001b[33m\"\u001b[39m\u001b[33mTranslate input to English.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py:1447\u001b[39m, in \u001b[36mOpenAIChatCompletionClient.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m copied_args \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mLLAMA_API_KEY\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m   1445\u001b[39m         copied_args[\u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m] = os.environ[\u001b[33m\"\u001b[39m\u001b[33mLLAMA_API_KEY\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m client = \u001b[43m_openai_client_from_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopied_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1448\u001b[39m create_args = _create_args_from_config(copied_args)\n\u001b[32m   1450\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m   1451\u001b[39m     client=client,\n\u001b[32m   1452\u001b[39m     create_args=create_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1455\u001b[39m     add_name_prefixes=add_name_prefixes,\n\u001b[32m   1456\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py:134\u001b[39m, in \u001b[36m_openai_client_from_config\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_openai_client_from_config\u001b[39m(config: Mapping[\u001b[38;5;28mstr\u001b[39m, Any]) -> AsyncOpenAI:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Shave down the config to just the OpenAI kwargs\u001b[39;00m\n\u001b[32m    133\u001b[39m     openai_config = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m config.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m openai_init_kwargs}\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopenai_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_client.py:449\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    447\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    450\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    451\u001b[39m     )\n\u001b[32m    452\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "from autogen_agentchat.teams import DiGraphBuilder, GraphFlow\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "\n",
    "\n",
    "# Create the token provider\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(),\n",
    "    \"https://cognitiveservices.azure.com/.default\",\n",
    ")\n",
    "\n",
    "model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    azure_endpoint=\"https://azopenai-langchain.openai.azure.com/\",\n",
    "    azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    # api_key=\"sk-...\", # For key-based authentication.\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "async def main():\n",
    "    # Initialize agents with OpenAI model clients.\n",
    "    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1-nano\")\n",
    "    agent_a = AssistantAgent(\n",
    "        \"A\",\n",
    "        model_client=model_client,\n",
    "        system_message=\"Detect if the input is in Chinese. If it is, say 'yes', else say 'no', and nothing else.\",\n",
    "    )\n",
    "    agent_b = AssistantAgent(\"B\", model_client=model_client, system_message=\"Translate input to English.\")\n",
    "    agent_c = AssistantAgent(\"C\", model_client=model_client, system_message=\"Translate input to Chinese.\")\n",
    "\n",
    "    # Create a directed graph with conditional branching flow A -> B (\"yes\"), A -> C (otherwise).\n",
    "    builder = DiGraphBuilder()\n",
    "    builder.add_node(agent_a).add_node(agent_b).add_node(agent_c)\n",
    "    # Create conditions as callables that check the message content.\n",
    "    builder.add_edge(agent_a, agent_b, condition=lambda msg: \"yes\" in msg.to_model_text())\n",
    "    builder.add_edge(agent_a, agent_c, condition=lambda msg: \"yes\" not in msg.to_model_text())\n",
    "    graph = builder.build()\n",
    "\n",
    "    # Create a GraphFlow team with the directed graph.\n",
    "    team = GraphFlow(\n",
    "        participants=[agent_a, agent_b, agent_c],\n",
    "        graph=graph,\n",
    "        termination_condition=MaxMessageTermination(5),\n",
    "    )\n",
    "\n",
    "    # Run the team and print the events.\n",
    "    async for event in team.run_stream(task=\"AutoGen is a framework for building AI agents.\"):\n",
    "        print(event)\n",
    "\n",
    "\n",
    "await main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
