{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a891cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import AzureOpenAIChatCompletionClient\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import asyncio\n",
    "from pydantic import BaseModel,Field\n",
    "from autogen_ext.tools.http import HttpTool\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "from autogen_agentchat.base import TaskResult\n",
    "\n",
    "\n",
    "\n",
    "# Create the token provider\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(),\n",
    "    \"https://cognitiveservices.azure.com/.default\",\n",
    ")\n",
    "\n",
    "az_model_client = AzureOpenAIChatCompletionClient(\n",
    "    azure_deployment=\"gpt-4o-mini\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-08-01-preview\",\n",
    "    azure_endpoint=\"https://azopenai-langchain.openai.azure.com/\",\n",
    "    azure_ad_token_provider=token_provider,  # Optional if you choose key-based authentication.\n",
    "    # api_key=\"sk-...\", # For key-based authentication.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "15f84417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agent definition\n",
    "# Define a simple tool that can be used by the agent\n",
    "dsa_solver_agent = AssistantAgent(\n",
    "    name=\"dsa_solver\",\n",
    "    description=\"A DSA solver agent that can answer questions related to data structures and algorithms.\",\n",
    "    system_message= \" You give code snippets to solve DSA problems. You are a DSA expert.\" ,\n",
    "    model_client=az_model_client\n",
    ")\n",
    "\n",
    "\n",
    "code_reviewer_agent = AssistantAgent(\n",
    "    name=\"code_reviewer\",\n",
    "    description=\"A code reviewer agent that can review code snippets and provide feedback.\",\n",
    "    system_message=\"You are a code reviewer. You review code snippets and provide feedback.\",   \n",
    "    model_client=az_model_client\n",
    ")\n",
    "\n",
    "\n",
    "code_editor_agent = AssistantAgent(\n",
    "    name=\"code_editor\",\n",
    "    description=\"A code editor agent that can edit code snippets and provide suggestions and Add comments. Give under 10 lines comments\",\n",
    "    system_message=\"You are a code editor. You edit code snippets and provide suggestions. If all looks good, you can say 'TERMINATE'.\",\n",
    "    model_client=az_model_client\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8d7a4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_team = [dsa_solver_agent, code_reviewer_agent, code_editor_agent]\n",
    "team = RoundRobinGroupChat(participants=agent_team,max_turns= 30,termination_condition=TextMentionTermination(\"TERMINATE\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cae51eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object BaseGroupChat.reset at 0x000002E15AF07240>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team.run_stream(task=\"Write a Python function to add 2 numbers.\")\n",
    "team.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a7ab02a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User\n",
      "--------------------------------------------------\n",
      "Team chat completed successfully.\n",
      "--------------------------------------------------\n",
      "code_editor\n",
      "--------------------------------------------------\n",
      "Team chat completed successfully.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async def run_team_chat(user_prompt):\n",
    "    text_message = TextMessage(content=user_prompt, source=\"User\")\n",
    "    response = await team.run(task=text_message)\n",
    "    for message in response.messages:\n",
    "        print(f\"{message.source }\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"Team chat completed successfully.\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "        \n",
    "\n",
    "# Example usage:\n",
    "await run_team_chat(\"Write a Python function to add 2 numbers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cdfe8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User\n",
      "--------------------------------------------------\n",
      "dsa_solver\n",
      "--------------------------------------------------\n",
      "Task Result: The group chat is stopped.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "async def run_team_chat(user_prompt):\n",
    "    text_message = TextMessage(content=user_prompt, source=\"User\")\n",
    "    async for message in team.run_stream(task=text_message):\n",
    "        if isinstance(message, TaskResult):\n",
    "           print(f\"Task Result: {message.stop_reason}\")\n",
    "        else:\n",
    "            print(f\"{message.source}\")\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "# Example usage:\n",
    "await run_team_chat(\"Write a Python function to add 2 numbers.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "209f5e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User\n",
      "--------------------------------------------------\n",
      "code_reviewer\n",
      "--------------------------------------------------\n",
      "Task Result: The group chat is stopped.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# The error in cell 6 is that run_team_chat() requires a user_prompt argument.\n",
    "# Provide a prompt string when calling the function.\n",
    "\n",
    "await run_team_chat(\"Write a Python program to check if a number is even.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0951a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = team.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2d4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<coroutine object BaseGroupChat.save_state at 0x000002E15AA2F240>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f06cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "Team Response: messages=[\n",
    "    \n",
    "    \n",
    "    TextMessage(id='40c64f35-a39b-4984-90e0-cbef7573b2db', source='User', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 53, 32, 905088, tzinfo=datetime.timezone.utc), content='Write a Python program to check if a number is even.', type='TextMessage'), \n",
    "    \n",
    "    TextMessage(id='67e7e1de-2a8c-48dc-b3c3-40564a2e934e', source='dsa_solver', models_usage=RequestUsage(prompt_tokens=183, completion_tokens=221), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 53, 35, 989842, tzinfo=datetime.timezone.utc), content='Certainly! Here’s a simple Python program to check if a number is even:\\n\\n```python\\ndef is_even(number):\\n    return number % 2 == 0\\n\\n# Input from the user\\ntry:\\n    user_input = int(input(\"Enter a number: \"))\\n    if is_even(user_input):\\n        print(f\"{user_input} is an even number.\")\\n    else:\\n        print(f\"{user_input} is an odd number.\")\\nexcept ValueError:\\n    print(\"Please enter a valid integer.\")\\n```\\n\\n### How It Works:\\n1. The function `is_even` takes a number as input and returns `True` if the number is even (i.e., divisible by 2 with no remainder), and `False` otherwise.\\n2. The program prompts the user to enter a number.\\n3. It checks whether the input is a valid integer, and then calls the `is_even` function to determine if the number is even or odd, printing the appropriate message to the user.\\n\\nFeel free to run this code and let me know if you have any questions or modifications in mind!', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    TextMessage(id='606eeca5-795b-4130-8b8d-751604f302ac', source='code_reviewer', models_usage=RequestUsage(prompt_tokens=406, completion_tokens=553), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 53, 45, 394097, tzinfo=datetime.timezone.utc), content='Your code for checking if a number is even is well-structured and effectively demonstrates the concept. Here are a few suggestions and feedback to consider for improvement:\\n\\n### Strengths:\\n1. **Functionality**: The program correctly implements the check for even and odd numbers.\\n2. **Error Handling**: You\\'ve included error handling for invalid inputs, which is an important aspect of user-friendly applications.\\n3. **Readability**: The code is easy to read and understand, thanks to clear function and variable names.\\n\\n### Suggestions for Improvement:\\n1. **Docstrings**: Consider adding a docstring to the `is_even` function to describe its purpose, parameters, and return value. This improves code documentation.\\n\\n   ```python\\n   def is_even(number):\\n       \"\"\"\\n       Check if a number is even.\\n\\n       Parameters:\\n       number (int): The number to check.\\n\\n       Returns:\\n       bool: True if the number is even, False otherwise.\\n       \"\"\"\\n       return number % 2 == 0\\n   ```\\n\\n2. **Integer Input Validation**: Although the `try-except` block handles invalid input, you may want to loop back to ask for input again instead of terminating the program. This makes it more user-friendly.\\n\\n    ```python\\n    while True:\\n        try:\\n            user_input = int(input(\"Enter a number: \"))\\n            break  # Exit the loop if the input is valid\\n        except ValueError:\\n            print(\"Please enter a valid integer.\")\\n    ```\\n\\n3. **Function Modularity**: While your code is concise, you could separate the input and output logic from the checking logic for better modularity.\\n\\n### Revised Code Example:\\nHere\\'s an updated version of your program incorporating these suggestions:\\n\\n```python\\ndef is_even(number):\\n    \"\"\"\\n    Check if a number is even.\\n\\n    Parameters:\\n    number (int): The number to check.\\n\\n    Returns:\\n    bool: True if the number is even, False otherwise.\\n    \"\"\"\\n    return number % 2 == 0\\n\\ndef main():\\n    while True:\\n        try:\\n            user_input = int(input(\"Enter a number: \"))\\n            break  # Exit the loop if the input is valid\\n        except ValueError:\\n            print(\"Please enter a valid integer.\")\\n    \\n    if is_even(user_input):\\n        print(f\"{user_input} is an even number.\")\\n    else:\\n        print(f\"{user_input} is an odd number.\")\\n\\nif __name__ == \"__main__\":\\n    main()\\n```\\n\\n### Conclusion:\\nYour initial code is great, and these enhancements will make it even more robust, user-friendly, and maintainable. If you have any further questions or specific areas you\\'d like to explore, feel free to ask!', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    TextMessage(id='b15bca37-9f87-4076-9c13-e36c7e396b99', source='code_editor', models_usage=RequestUsage(prompt_tokens=967, completion_tokens=552), metadata={}, created_at=datetime.datetime(2025, 7, 12, 4, 53, 49, 674140, tzinfo=datetime.timezone.utc), content='Your code for checking if a number is even is well-structured and effectively demonstrates the concept. Here are a few suggestions and feedback to consider for improvement:\\n\\n### Strengths:\\n1. **Functionality**: The program correctly implements the check for even and odd numbers.\\n2. **Error Handling**: You\\'ve included error handling for invalid inputs, which is an important aspect of user-friendly applications.\\n3. **Readability**: The code is easy to read and understand, thanks to clear function and variable names.\\n\\n### Suggestions for Improvement:\\n1. **Docstrings**: Consider adding a docstring to the `is_even` function to describe its purpose, parameters, and return value. This improves code documentation.\\n\\n   ```python\\n   def is_even(number):\\n       \"\"\"\\n       Check if a number is even.\\n\\n       Parameters:\\n       number (int): The number to check.\\n\\n       Returns:\\n       bool: True if the number is even, False otherwise.\\n       \"\"\"\\n       return number % 2 == 0\\n   ```\\n\\n2. **Integer Input Validation**: Although the `try-except` block handles invalid input, you may want to loop back to ask for input again instead of terminating the program. This makes it more user-friendly.\\n\\n    ```python\\n    while True:\\n        try:\\n            user_input = int(input(\"Enter a number: \"))\\n            break  # Exit the loop if the input is valid\\n        except ValueError:\\n            print(\"Please enter a valid integer.\")\\n    ```\\n\\n3. **Function Modularity**: While your code is concise, you could separate the input and output logic from the checking logic for better modularity.\\n\\n### Revised Code Example:\\nHere\\'s an updated version of your program incorporating these suggestions:\\n\\n```python\\ndef is_even(number):\\n    \"\"\"\\n    Check if a number is even.\\n\\n    Parameters:\\n    number (int): The number to check.\\n\\n    Returns:\\n    bool: True if the number is even, False otherwise.\\n    \"\"\"\\n    return number % 2 == 0\\n\\ndef main():\\n    while True:\\n        try:\\n            user_input = int(input(\"Enter a number: \"))\\n            break  # Exit the loop if the input is valid\\n        except ValueError:\\n            print(\"Please enter a valid integer.\")\\n\\n    if is_even(user_input):\\n        print(f\"{user_input} is an even number.\")\\n    else:\\n        print(f\"{user_input} is an odd number.\")\\n\\nif __name__ == \"__main__\":\\n    main()\\n```\\n\\n### Conclusion:\\nYour initial code is great, and these enhancements will make it even more robust, user-friendly, and maintainable. If you have any further questions or specific areas you\\'d like to explore, feel free to ask!', type='TextMessage')] \n",
    "\n",
    "\n",
    "stop_reason='Maximum number of turns 3 reached.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "88080c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the primary agent.\n",
    "primary_agent = AssistantAgent(\n",
    "    \"primary\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"You are a helpful AI assistant.\",\n",
    ")\n",
    "\n",
    "# Create the critic agent.\n",
    "critic_agent = AssistantAgent(\n",
    "    \"critic\",\n",
    "    model_client=az_model_client,\n",
    "    system_message=\"Provide constructive feedback. Respond with 'APPROVE' to when your feedbacks are addressed.\",\n",
    ")\n",
    "\n",
    "# Define a termination condition that stops the task if the critic approves.\n",
    "text_termination = TextMentionTermination(\"APPROVE\")\n",
    "\n",
    "# Create a team with the primary and critic agents.\n",
    "team = RoundRobinGroupChat([primary_agent, critic_agent], termination_condition=text_termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52fb7963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[TextMessage(id='59a77411-3868-4b53-937e-4f2b9f53176e', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 56, 53, 723819, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(id='8bd0c1fb-5ac1-4c97-840a-67dbeb3921cc', source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=143), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 3, 572683, tzinfo=datetime.timezone.utc), content=\"In autumn’s embrace, the leaves gently sway,  \\nA tapestry woven in golds, reds, and gray.  \\nCrisp whispers of wind through branches do weave,  \\nA dance of the seasons, as nature takes leave.  \\n\\nPumpkins adorn porches, their faces aglow,  \\nAs twilight invites a soft, warming flow.  \\nCider spills laughter, bright fires ignite,  \\nFleeting moments of warmth as the days turn to night.  \\n\\nBeneath a sky painted in twilight's soft hue,  \\nWe gather in joy, as the harvest shines through.  \\nEmbracing the chill, with hearts open wide,  \\nIn the beauty of fall, we find peace inside.\", type='TextMessage'), TextMessage(id='2d4ff2dd-1384-4530-ac5b-9a1dde6655a3', source='critic', models_usage=RequestUsage(prompt_tokens=188, completion_tokens=157), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 5, 494240, tzinfo=datetime.timezone.utc), content='This poem beautifully captures the essence of the fall season with vivid imagery and a strong sense of warmth and togetherness. A few suggestions for enhancement:\\n\\n1. **Imagery**: Consider adding a specific image or symbol that is unique to autumn in a particular region or culture. This could help ground the poem in a specific experience.\\n\\n2. **Rhythm**: The poem flows well, but there are a couple of lines where the rhythm feels slightly off. Pay attention to the syllable count to maintain a consistent rhythm throughout.\\n\\n3. **Emotion**: While the poem conveys warmth and joy, exploring a contrasting emotion, like the bittersweet nature of change, could add depth.\\n\\nOverall, it’s a lovely piece! With a few tweaks, it could shine even brighter.', type='TextMessage'), TextMessage(id='07a43ef4-ad5f-4429-af66-88e73d8077af', source='primary', models_usage=RequestUsage(prompt_tokens=336, completion_tokens=200), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 7, 349687, tzinfo=datetime.timezone.utc), content=\"Thank you for your thoughtful critique! Here’s a revised version of the poem, incorporating your suggestions:\\n\\n---\\n\\nIn autumn’s embrace, where the chestnuts fall down,  \\nGolden leaves drift softly, a quilt for the ground.  \\nPumpkins grinning wide on porches aglow,  \\nWhile apple harvest whispers of cider's warm flow.  \\n\\nCrisp whispers of wind through the branches entwine,  \\nA dance of the seasons, as daylight declines.  \\nMisty evenings gather, and shadows grow long,  \\nAs we share stories, weaving laughter in song.  \\n\\nYet in this bright tapestry, bittersweet lingers,  \\nThe fleetingness of warmth held softly in fingers.  \\nBut under the twilight, with hearts open wide,  \\nIn the beauty of fall, we find peace inside.\\n\\n---\\n\\nI've added a reference to chestnuts and adjusted the rhythm for a more consistent flow. The line about bittersweet emotions introduces a contrast to enhance the depth. Thank you again for your feedback!\", type='TextMessage'), TextMessage(id='34081d68-40f5-4fce-8be9-031c3c141cd4', source='critic', models_usage=RequestUsage(prompt_tokens=553, completion_tokens=93), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 8, 457591, tzinfo=datetime.timezone.utc), content=\"This revised version of the poem is fantastic! The incorporation of chestnuts adds a wonderful regional touch, and the improved rhythm creates a more harmonious flow throughout. The addition of the bittersweet element indeed deepens the emotional resonance of the piece, making it more relatable and reflective of the fall season's complexity. \\n\\nThe imagery is vivid and inviting, and the overall tone is balanced beautifully between warmth and reflection. \\n\\nGreat job addressing the feedback! \\n\\nAPPROVE\", type='TextMessage')] stop_reason=\"Text 'APPROVE' mentioned\"\n"
     ]
    }
   ],
   "source": [
    "# Use `asyncio.run(...)` when running in a script.\n",
    "result = await team.run(task=\"Write a short poem about the fall season.\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892bc2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    \n",
    "    \n",
    "    TextMessage(id='59a77411-3868-4b53-937e-4f2b9f53176e', source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 56, 53, 723819, tzinfo=datetime.timezone.utc), content='Write a short poem about the fall season.', type='TextMessage'), TextMessage(id='8bd0c1fb-5ac1-4c97-840a-67dbeb3921cc', source='primary', models_usage=RequestUsage(prompt_tokens=28, completion_tokens=143), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 3, 572683, tzinfo=datetime.timezone.utc), content=\"In autumn’s embrace, the leaves gently sway,  \\nA tapestry woven in golds, reds, and gray.  \\nCrisp whispers of wind through branches do weave,  \\nA dance of the seasons, as nature takes leave.  \\n\\nPumpkins adorn porches, their faces aglow,  \\nAs twilight invites a soft, warming flow.  \\nCider spills laughter, bright fires ignite,  \\nFleeting moments of warmth as the days turn to night.  \\n\\nBeneath a sky painted in twilight's soft hue,  \\nWe gather in joy, as the harvest shines through.  \\nEmbracing the chill, with hearts open wide,  \\nIn the beauty of fall, we find peace inside.\", type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    TextMessage(id='2d4ff2dd-1384-4530-ac5b-9a1dde6655a3', source='critic', models_usage=RequestUsage(prompt_tokens=188, completion_tokens=157), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 5, 494240, tzinfo=datetime.timezone.utc), content='This poem beautifully captures the essence of the fall season with vivid imagery and a strong sense of warmth and togetherness. A few suggestions for enhancement:\\n\\n1. **Imagery**: Consider adding a specific image or symbol that is unique to autumn in a particular region or culture. This could help ground the poem in a specific experience.\\n\\n2. **Rhythm**: The poem flows well, but there are a couple of lines where the rhythm feels slightly off. Pay attention to the syllable count to maintain a consistent rhythm throughout.\\n\\n3. **Emotion**: While the poem conveys warmth and joy, exploring a contrasting emotion, like the bittersweet nature of change, could add depth.\\n\\nOverall, it’s a lovely piece! With a few tweaks, it could shine even brighter.', type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    TextMessage(id='07a43ef4-ad5f-4429-af66-88e73d8077af', source='primary', models_usage=RequestUsage(prompt_tokens=336, completion_tokens=200), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 7, 349687, tzinfo=datetime.timezone.utc), content=\"Thank you for your thoughtful critique! Here’s a revised version of the poem, incorporating your suggestions:\\n\\n---\\n\\nIn autumn’s embrace, where the chestnuts fall down,  \\nGolden leaves drift softly, a quilt for the ground.  \\nPumpkins grinning wide on porches aglow,  \\nWhile apple harvest whispers of cider's warm flow.  \\n\\nCrisp whispers of wind through the branches entwine,  \\nA dance of the seasons, as daylight declines.  \\nMisty evenings gather, and shadows grow long,  \\nAs we share stories, weaving laughter in song.  \\n\\nYet in this bright tapestry, bittersweet lingers,  \\nThe fleetingness of warmth held softly in fingers.  \\nBut under the twilight, with hearts open wide,  \\nIn the beauty of fall, we find peace inside.\\n\\n---\\n\\nI've added a reference to chestnuts and adjusted the rhythm for a more consistent flow. The line about bittersweet emotions introduces a contrast to enhance the depth. Thank you again for your feedback!\", type='TextMessage'), \n",
    "    \n",
    "    \n",
    "    \n",
    "    TextMessage(id='34081d68-40f5-4fce-8be9-031c3c141cd4', source='critic', models_usage=RequestUsage(prompt_tokens=553, completion_tokens=93), metadata={}, created_at=datetime.datetime(2025, 7, 13, 2, 57, 8, 457591, tzinfo=datetime.timezone.utc), content=\"This revised version of the poem is fantastic! The incorporation of chestnuts adds a wonderful regional touch, and the improved rhythm creates a more harmonious flow throughout. The addition of the bittersweet element indeed deepens the emotional resonance of the piece, making it more relatable and reflective of the fall season's complexity. \\n\\nThe imagery is vivid and inviting, and the overall tone is balanced beautifully between warmth and reflection. \\n\\nGreat job addressing the feedback! \\n\\nAPPROVE\", type='TextMessage')] stop_reason=\"Text 'APPROVE' mentioned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "36cfe955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='6bc41c09-16c0-40ca-8377-b8eb695fdac1' source='user' models_usage=None metadata={} created_at=datetime.datetime(2025, 7, 13, 3, 19, 53, 466945, tzinfo=datetime.timezone.utc) content='Write a short poem about the fall season.' type='TextMessage'\n",
      "id='4cbd42e1-c0d8-4b20-92d6-26d085395a5e' source='dsa_solver' models_usage=RequestUsage(prompt_tokens=38, completion_tokens=140) metadata={} created_at=datetime.datetime(2025, 7, 13, 3, 20, 3, 135057, tzinfo=datetime.timezone.utc) content=\"In autumn's embrace, the leaves gently fall,  \\nA tapestry woven, the earth's vibrant sprawl.  \\nGolds, reds, and oranges dance in the breeze,  \\nWhispers of harvest in rustling trees.  \\n\\nCrisp air carries scents of pumpkin delight,  \\nAs sunsets paint skies in a warm, amber light.  \\nSweaters come out, hot cider in hand,  \\nIn the season of change, where nature has planned.  \\n\\nFields bow in gratitude, as twilight descends,  \\nCozy nights beckon, where warmth never ends.  \\nIn the glow of the harvest, we gather and share,  \\nThe magic of fall fills the cool evening air.  \" type='TextMessage'\n",
      "Stop Reason: The group chat is stopped.\n"
     ]
    }
   ],
   "source": [
    "# When running inside a script, use a async main function and call it from `asyncio.run(...)`.\n",
    "await team.reset()  # Reset the team for a new task.\n",
    "async for message in team.run_stream(task=\"Write a short poem about the fall season.\"):  # type: ignore\n",
    "    if isinstance(message, TaskResult):\n",
    "        print(\"Stop Reason:\", message.stop_reason)\n",
    "    else:\n",
    "        print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2e1525d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a 2 lines poem about the fall season.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for primary_a07b3aef-3129-45dd-8ed9-8267a27693a0/a07b3aef-3129-45dd-8ed9-8267a27693a0\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        pool_request.request\n",
      "        ^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 78, in handle_async_request\n",
      "    stream = await self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 124, in _connect\n",
      "    stream = await self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_backends\\auto.py\", line 31, in connect_tcp\n",
      "    return await self._backend.connect_tcp(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 113, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "         ~~~~~~~~~~~~~~^^^^^^^^^\n",
      "  File \"C:\\Users\\vnallava\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n",
      "    response = await self._client.send(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n",
      "    with map_httpcore_exceptions():\n",
      "         ~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"C:\\Users\\vnallava\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n",
      "    self.gen.throw(value)\n",
      "    ~~~~~~~~~~~~~~^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [Errno 11001] getaddrinfo failed\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "    ...<4 lines>...\n",
      "            await self._log_message(msg)\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 964, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "    ...<15 lines>...\n",
      "            yield inference_output\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1118, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "                                                                     ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2454, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "    ...<45 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1784, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1551, in request\n",
      "    raise APIConnectionError(request=request) from err\n",
      "openai.APIConnectionError: Connection error.\n",
      "Error processing publish message for critic_a07b3aef-3129-45dd-8ed9-8267a27693a0/a07b3aef-3129-45dd-8ed9-8267a27693a0\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 606, in _on_message\n",
      "    return await agent.on_message(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<2 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 72, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_core\\_routed_agent.py\", line 486, in on_message_impl\n",
      "    return await self.on_unhandled_message(message, ctx)  # type: ignore\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 138, in on_unhandled_message\n",
      "    raise ValueError(f\"Unhandled message in agent container: {type(message)}\")\n",
      "ValueError: Unhandled message in agent container: <class 'autogen_agentchat.teams._group_chat._events.GroupChatError'>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "APIConnectionError: Connection error.\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        pool_request.request\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n    raise exc\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 78, in handle_async_request\n    stream = await self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 124, in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_backends\\auto.py\", line 31, in connect_tcp\n    return await self._backend.connect_tcp(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 113, in connect_tcp\n    with map_exceptions(exc_map):\n         ~~~~~~~~~~~~~~^^^^^^^^^\n\n  File \"C:\\Users\\vnallava\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\n\nhttpcore.ConnectError: [Errno 11001] getaddrinfo failed\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n         ~~~~~~~~~~~~~~~~~~~~~~~^^\n\n  File \"C:\\Users\\vnallava\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n\nhttpx.ConnectError: [Errno 11001] getaddrinfo failed\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 964, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1118, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1784, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1551, in request\n    raise APIConnectionError(request=request) from err\n\nopenai.APIConnectionError: Connection error.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m external_termination.set()\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Wait for the team to finish.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\ui\\_console.py:117\u001b[39m, in \u001b[36mConsole\u001b[39m\u001b[34m(stream, no_inline_images, output_stats, user_input_manager)\u001b[39m\n\u001b[32m    113\u001b[39m last_processed: Optional[T] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    115\u001b[39m streaming_chunks: List[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, TaskResult):\n\u001b[32m    119\u001b[39m         duration = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_base_group_chat.py:522\u001b[39m, in \u001b[36mBaseGroupChat.run_stream\u001b[39m\u001b[34m(self, task, cancellation_token, output_task_messages)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, GroupChatTermination):\n\u001b[32m    519\u001b[39m     \u001b[38;5;66;03m# If the message contains an error, we need to raise it here.\u001b[39;00m\n\u001b[32m    520\u001b[39m     \u001b[38;5;66;03m# This will stop the team and propagate the error.\u001b[39;00m\n\u001b[32m    521\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m522\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(message.error))\n\u001b[32m    523\u001b[39m     stop_reason = message.message.content\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: APIConnectionError: Connection error.\nTraceback:\nTraceback (most recent call last):\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 101, in map_httpcore_exceptions\n    yield\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n    resp = await self._pool.handle_async_request(req)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n    raise exc from None\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n    response = await connection.handle_async_request(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n        pool_request.request\n        ^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 101, in handle_async_request\n    raise exc\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 78, in handle_async_request\n    stream = await self._connect(request)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_async\\connection.py\", line 124, in _connect\n    stream = await self._network_backend.connect_tcp(**kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_backends\\auto.py\", line 31, in connect_tcp\n    return await self._backend.connect_tcp(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 113, in connect_tcp\n    with map_exceptions(exc_map):\n         ~~~~~~~~~~~~~~^^^^^^^^^\n\n  File \"C:\\Users\\vnallava\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n    raise to_exc(exc) from exc\n\nhttpcore.ConnectError: [Errno 11001] getaddrinfo failed\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1519, in request\n    response = await self._client.send(\n               ^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n    response = await self._send_handling_auth(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n    response = await self._send_handling_redirects(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<3 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n    response = await self._send_single_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n    response = await transport.handle_async_request(request)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 393, in handle_async_request\n    with map_httpcore_exceptions():\n         ~~~~~~~~~~~~~~~~~~~~~~~^^\n\n  File \"C:\\Users\\vnallava\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py\", line 162, in __exit__\n    self.gen.throw(value)\n    ~~~~~~~~~~~~~~^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 118, in map_httpcore_exceptions\n    raise mapped_exc(message) from exc\n\nhttpx.ConnectError: [Errno 11001] getaddrinfo failed\n\n\nThe above exception was the direct cause of the following exception:\n\n\nTraceback (most recent call last):\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 84, in handle_request\n    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n    ...<4 lines>...\n            await self._log_message(msg)\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 964, in on_messages_stream\n    async for inference_output in self._call_llm(\n    ...<15 lines>...\n            yield inference_output\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 1118, in _call_llm\n    model_result = await model_client.create(\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^\n    ...<4 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 676, in create\n    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n                                                                     ^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2454, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n    ...<45 lines>...\n    )\n    ^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1784, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"c:\\Users\\vnallava\\OneDrive - Insight\\Desktop\\Learning\\AiAgent-AutoGen\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1551, in request\n    raise APIConnectionError(request=request) from err\n\nopenai.APIConnectionError: Connection error.\n"
     ]
    }
   ],
   "source": [
    "## External termination User ExternalTermination() method and call .set() to stop the team.\n",
    "\n",
    "from autogen_agentchat.conditions import ExternalTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "# Create a new team with an external termination condition.\n",
    "external_termination = ExternalTermination()\n",
    "team = RoundRobinGroupChat(\n",
    "    [primary_agent, critic_agent],\n",
    "    termination_condition=external_termination | text_termination,  # Use the bitwise OR operator to combine conditions.\n",
    ")\n",
    "\n",
    "await team.reset()\n",
    "\n",
    "# Run the team in a background task.\n",
    "run = asyncio.create_task(Console(team.run_stream(task=\"Write a 2 lines poem about the fall season.\")))\n",
    "\n",
    "# Wait for some time.\n",
    "await asyncio.sleep(0.1)\n",
    "\n",
    "# Stop the team.\n",
    "external_termination.set()\n",
    "\n",
    "# Wait for the team to finish.\n",
    "await run\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
